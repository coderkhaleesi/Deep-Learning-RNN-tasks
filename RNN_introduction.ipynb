{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN-introduction.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanyadixit21/Deep-Learning-RNN-tasks/blob/master/RNN_introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "0cdQvSrtGJj4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this notebook we discuss different RNN architectures and see many optimization techniques as well.\n",
        "\n",
        "For data, we have many options like the nltk.corpus package\n",
        "https://www.nltk.org/book/ch02.html\n",
        "\n",
        "We will use the brown dataset.\n",
        "\n",
        "https://www.nltk.org/book/ch05.html\n"
      ]
    },
    {
      "metadata": {
        "id": "R9NHGifxKpti",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "9b1e9b85-fa65-4e37-e2b3-82c3e5b25186"
      },
      "cell_type": "code",
      "source": [
        "!pip install sklearn"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.20.3)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.14.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Fr0mZQw4GDKI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "12244435-06f3-4e4f-8278-776215653a13"
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import sys\n",
        "import numpy as np\n",
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "yIayQ7FnG5NP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = nltk.corpus.brown.tagged_sents(tagset='universal') #this will give sentences, use nltk.corpus.brown.tagged_words(tagset='universal') for random words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PB4J2T5yG5Qr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_tags = ['#EOS#','#UNK#','ADV', 'NOUN', 'ADP', 'PRON', 'DET', '.', 'PRT', 'VERB', 'X', 'NUM', 'CONJ', 'ADJ']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YWPvgIfGG5T6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = np.asarray([[(word.lower(), tag) for word, tag in sentence] for sentence in data])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "faGS1QjRG5XJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data,test_data = train_test_split(data,test_size=0.25,random_state=42) #split into train and test dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WoGm6c3CG5Z_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KNsx0qxiMf-T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word_counter = Counter()\n",
        "\n",
        "for sentence in data: #since data is an array of sentences\n",
        "  words, tags = zip(*sentence) #extract the words and tags individually\n",
        "  word_counter.update(words)\n",
        "  \n",
        "\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t28bLblNMgA2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e8b841f4-b052-48c4-ebab-a081b3e9a2cf"
      },
      "cell_type": "code",
      "source": [
        "all_words = ['#EOS#','#UNK#'] + list(list(zip(*word_counter.most_common(20000)))[0])#to make it an array\n",
        "\n",
        "#let's measure what fraction of data words are in the dictionary\n",
        "print(\"Coverage = %.5f\"%(float(sum(word_counter[w] for w in all_words)) / sum(word_counter.values())))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Coverage = 0.96707\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J4lYwivWQRu2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "word_to_id = defaultdict(lambda:1 , {word:i for i,word in enumerate(all_words)}) #we use default value as 1 as the id for words not in dictionary\n",
        "tag_to_id = {tag:i for i,tag in enumerate(all_tags)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZHbhgBoDRN05",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Till this point, we have our words, our tags and our ids. Now we need to create matrices for input as well as output."
      ]
    },
    {
      "metadata": {
        "id": "7ry9ph11MgNF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_matrix(lines,token_to_id,max_len=None,pad=0,dtype='int32',time_major=False):\n",
        "    \"\"\"Converts a list of names into rnn-digestable matrix with paddings added after the end\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len,lines))\n",
        "    matrix = np.empty([len(lines),max_len],dtype)\n",
        "    matrix.fill(pad)\n",
        "\n",
        "   \n",
        "    \n",
        "    for i in range(len(lines)):\n",
        "        line_ix = list(map(token_to_id.__getitem__,lines[i]))[:max_len]\n",
        "        matrix[i,:len(line_ix)] = line_ix\n",
        "\n",
        "    return matrix.T if time_major else matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-0D0YIG1MgQI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "46daf8c2-353f-4454-f975-cdbb8beafb70"
      },
      "cell_type": "code",
      "source": [
        "batch_words,batch_tags = zip(*[zip(*sentence) for sentence in data[-3:]]) #3 sentences for testing\n",
        "\n",
        "print(\"Word ids:\")\n",
        "print(to_matrix(batch_words,word_to_id))\n",
        "print(to_matrix(batch_words,word_to_id).shape)\n",
        "print(\"Tag ids:\")\n",
        "print(to_matrix(batch_tags,tag_to_id))\n",
        "print(to_matrix(batch_tags,tag_to_id).shape)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word ids:\n",
            "[[    2  3057     5     2  2238  1334  4238  2454     3     6    19    26\n",
            "   1070    69     8  2088     6     3     1     3   266    65   342     2\n",
            "  11533     3     2   315     1     9    87   216  3322    69  1558     4\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0]\n",
            " [   45    12     8   511  8419     6    60  3246    39     2     1 10137\n",
            "      3     2   845 14205     3     1     3    10  9910     2     1  3470\n",
            "      9    43 11939     1     3     6     2  1046   385    73  4562     3\n",
            "      9     2 19492 18192  3250     3    12    10     2   861  5240    12\n",
            "      8  8936   121 19416     4]\n",
            " [   33    64    26    12   445     7  7346     9     8  3337     3 13074\n",
            "   2811     3     2   463   572     2     1     1  1649    12     1     4\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0]]\n",
            "(3, 53)\n",
            "Tag ids:\n",
            "[[ 6  3  4  6  3  3  9  9  7 12  4  5  9  4  6  3 12  7  9  7  9  8  4  6\n",
            "   3  7  6 13  3  4  6  3  9  4  3  7  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0]\n",
            " [ 5  9  6  9  3 12  6  3  7  6 13  3  7  6 13  3  7 13  7  5  9  6  3  3\n",
            "   4  6 13  3  7 12  6  3  6 13  3  7  4  6  3  9  3  7  9  4  6 13  3  9\n",
            "   6  3  2 13  7]\n",
            " [ 4  6  5  9 13  4  3  4  6 13  7 13  3  7  6  3  4  6 13  3  3  9  9  7\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0]]\n",
            "(3, 53)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MoP6HWvFMgMD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "d974c225-4eb0-4ef3-d206-683c1b65daf5"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import keras.layers as L\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(L.InputLayer([None],dtype='int32'))\n",
        "model.add(L.Embedding(len(all_words),50))\n",
        "model.add(L.SimpleRNN(64,return_sequences=True))\n",
        "\n",
        "#add top layer that predicts tag probabilities\n",
        "stepwise_dense = L.Dense(len(all_tags),activation='softmax')\n",
        "stepwise_dense = L.TimeDistributed(stepwise_dense)\n",
        "model.add(stepwise_dense)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iyIzQXHNaeKg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Batch Training\n",
        "\n",
        "Training: in this case we don't want to prepare the whole training dataset in advance. The main cause is that the length of every batch depends on the maximum sentence length within the batch. This leaves us two options: use custom training code or use generators.\n",
        "\n",
        "Keras models have a model.fit_generator method that accepts a python generator yielding one batch at a time. But first we need to implement such generator:"
      ]
    },
    {
      "metadata": {
        "id": "02MgO0obMgLI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "BATCH_SIZE=32\n",
        "def generate_batches(sentences,batch_size=BATCH_SIZE,max_len=None,pad=0):\n",
        "    assert isinstance(sentences,np.ndarray),\"Make sure sentences is a numpy array\"\n",
        "    \n",
        "    while True:\n",
        "        indices = np.random.permutation(np.arange(len(sentences)))\n",
        "        for start in range(0,len(indices)-1,batch_size):\n",
        "            batch_indices = indices[start:start+batch_size]\n",
        "            batch_words,batch_tags = [],[]\n",
        "            for sent in sentences[batch_indices]:\n",
        "                words,tags = zip(*sent)\n",
        "                batch_words.append(words)\n",
        "                batch_tags.append(tags)\n",
        "\n",
        "            batch_words = to_matrix(batch_words,word_to_id,max_len,pad)\n",
        "            batch_tags = to_matrix(batch_tags,tag_to_id,max_len,pad)\n",
        "\n",
        "            batch_tags_1hot = to_categorical(batch_tags,len(all_tags)).reshape(batch_tags.shape+(-1,))\n",
        "            yield batch_words,batch_tags_1hot\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "79xYIFRidFe_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://adventuresinmachinelearning.com/keras-lstm-tutorial/"
      ]
    },
    {
      "metadata": {
        "id": "lDt5AXp5MgKJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compute_test_accuracy(model):\n",
        "    test_words,test_tags = zip(*[zip(*sentence) for sentence in test_data])\n",
        "    test_words,test_tags = to_matrix(test_words,word_to_id),to_matrix(test_tags,tag_to_id)\n",
        "\n",
        "    #predict tag probabilities of shape [batch,time,n_tags]\n",
        "    predicted_tag_probabilities = model.predict(test_words,verbose=1)\n",
        "    predicted_tags = predicted_tag_probabilities.argmax(axis=-1)\n",
        "\n",
        "    #compute accurary excluding padding\n",
        "    numerator = np.sum(np.logical_and((predicted_tags == test_tags),(test_words != 0)))\n",
        "    denominator = np.sum(test_words != 0)\n",
        "    return float(numerator)/denominator\n",
        "\n",
        "\n",
        "class EvaluateAccuracy(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self,epoch,logs=None):\n",
        "        sys.stdout.flush()\n",
        "        print(\"\\nMeasuring validation accuracy...\")\n",
        "        acc = compute_test_accuracy(self.model)\n",
        "        print(\"\\nValidation accuracy: %.5f\\n\"%acc)\n",
        "        sys.stdout.flush()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p4rQk3Y_MgDP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "outputId": "c2c9c620-df76-4138-87b5-1e2f1ad27c7c"
      },
      "cell_type": "code",
      "source": [
        "model.compile('adam','categorical_crossentropy')\n",
        "\n",
        "model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n",
        "                    callbacks=[EvaluateAccuracy()], epochs=5,)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/5\n",
            "1344/1343 [==============================] - 37s 28ms/step - loss: 0.2448\n",
            "\n",
            "Measuring validation accuracy...\n",
            "14335/14335 [==============================] - 5s 338us/step\n",
            "\n",
            "Validation accuracy: 0.95008\n",
            "\n",
            "Epoch 2/5\n",
            "1344/1343 [==============================] - 39s 29ms/step - loss: 0.0460\n",
            "\n",
            "Measuring validation accuracy...\n",
            "14335/14335 [==============================] - 5s 330us/step\n",
            "\n",
            "Validation accuracy: 0.95560\n",
            "\n",
            "Epoch 3/5\n",
            "1344/1343 [==============================] - 39s 29ms/step - loss: 0.0382\n",
            "\n",
            "Measuring validation accuracy...\n",
            "14335/14335 [==============================] - 5s 331us/step\n",
            "\n",
            "Validation accuracy: 0.95692\n",
            "\n",
            "Epoch 4/5\n",
            "1344/1343 [==============================] - 40s 30ms/step - loss: 0.0331\n",
            "\n",
            "Measuring validation accuracy...\n",
            "14335/14335 [==============================] - 5s 333us/step\n",
            "\n",
            "Validation accuracy: 0.95593\n",
            "\n",
            "Epoch 5/5\n",
            "1344/1343 [==============================] - 40s 29ms/step - loss: 0.0282\n",
            "\n",
            "Measuring validation accuracy...\n",
            "14335/14335 [==============================] - 5s 331us/step\n",
            "\n",
            "Validation accuracy: 0.95473\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8f5470bf60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "7wpWaRSta8Ce",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f1f18eb9-b1a6-4b3a-caf2-eecc0196bfee"
      },
      "cell_type": "code",
      "source": [
        "acc = compute_test_accuracy(model)\n",
        "print(\"Final accuracy: %.5f\"%acc)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14335/14335 [==============================] - 5s 334us/step\n",
            "Final accuracy: 0.95473\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9hyNdqZUa8Np",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "birnn = keras.models.Sequential()\n",
        "birnn.add(L.InputLayer([None],dtype='int32'))\n",
        "birnn.add(L.Embedding(len(all_words),50))\n",
        "birnn.add(L.Bidirectional(L.SimpleRNN(64,return_sequences=True), merge_mode='concat', weights=None))\n",
        "\n",
        "#add top layer that predicts tag probabilities\n",
        "stepwise_dense = L.Dense(len(all_tags),activation='softmax')\n",
        "stepwise_dense = L.TimeDistributed(stepwise_dense)\n",
        "birnn.add(stepwise_dense)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EmLaGVRla8P5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "2f21ed5e-87d4-45c4-fd27-d9a805ca792c"
      },
      "cell_type": "code",
      "source": [
        "birnn.compile('adam','categorical_crossentropy')\n",
        "\n",
        "birnn.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n",
        "                    callbacks=[EvaluateAccuracy()], epochs=5,)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1344/1343 [==============================] - 60s 44ms/step - loss: 0.1961\n",
            "\n",
            "Measuring validation accuracy...\n",
            "14335/14335 [==============================] - 11s 745us/step\n",
            "\n",
            "Validation accuracy: 0.96479\n",
            "\n",
            "Epoch 2/5\n",
            "1344/1343 [==============================] - 57s 42ms/step - loss: 0.0331\n",
            "\n",
            "Measuring validation accuracy...\n",
            "14335/14335 [==============================] - 10s 715us/step\n",
            "\n",
            "Validation accuracy: 0.96930\n",
            "\n",
            "Epoch 3/5\n",
            "1344/1343 [==============================] - 57s 42ms/step - loss: 0.0245\n",
            "\n",
            "Measuring validation accuracy...\n",
            "14335/14335 [==============================] - 10s 729us/step\n",
            "\n",
            "Validation accuracy: 0.96977\n",
            "\n",
            "Epoch 4/5\n",
            "1344/1343 [==============================] - 57s 42ms/step - loss: 0.0188\n",
            "\n",
            "Measuring validation accuracy...\n",
            "14335/14335 [==============================] - 10s 714us/step\n",
            "\n",
            "Validation accuracy: 0.97004\n",
            "\n",
            "Epoch 5/5\n",
            "1344/1343 [==============================] - 56s 41ms/step - loss: 0.0139\n",
            "\n",
            "Measuring validation accuracy...\n",
            "14335/14335 [==============================] - 10s 715us/step\n",
            "\n",
            "Validation accuracy: 0.96920\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8f5470bb00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "metadata": {
        "id": "Oy_nTSIqa8Ss",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "349c2dec-f4bd-4f79-de95-1f402ff7ffc3"
      },
      "cell_type": "code",
      "source": [
        "acc = compute_test_accuracy(model)\n",
        "print(\"Final accuracy: %.5f\"%acc)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14335/14335 [==============================] - 5s 315us/step\n",
            "Final accuracy: 0.95473\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ux92jXxhkkm7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "1dbfba45-5d50-4e3d-e05d-ad5a44dba39d"
      },
      "cell_type": "code",
      "source": [
        "!pip install theano\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: theano in /usr/local/lib/python3.6/dist-packages (1.0.4)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from theano) (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from theano) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from theano) (1.11.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1F8dLqRCg94K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "7b8a03e9-be06-4e76-b467-cbf624e60352"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "bi_lstm = keras.models.Sequential()\n",
        "bi_lstm.add(L.InputLayer([None],dtype='int32'))\n",
        "bi_lstm.add(L.Embedding(len(all_words),50))\n",
        "bi_lstm.add(L.LSTM(64, recurrent_initializer='orthogonal'))\n",
        "\n",
        "#add top layer that predicts tag probabilities\n",
        "stepwise_dense = L.Dense(len(all_tags),activation='softmax')\n",
        "stepwise_dense = L.TimeDistributed(stepwise_dense)\n",
        "bi_lstm.add(stepwise_dense)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-0de9723c6824>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mstepwise_dense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mstepwise_dense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeDistributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstepwise_dense\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mbi_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstepwise_dense\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m                                          \u001b[0;34m'You can build it manually via: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[0;32m--> 431\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/wrappers.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mchild_input_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "kmHJb5ALg97w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "58f6071f-aa2f-491f-8296-39f98cc2383b"
      },
      "cell_type": "code",
      "source": [
        "bi_lstm.compile('adam','categorical_crossentropy')\n",
        "\n",
        "bi_lstm.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n",
        "                    callbacks=[EvaluateAccuracy()], epochs=5,)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-02af7a3a5dbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbi_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m bi_lstm.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n\u001b[1;32m      4\u001b[0m                     callbacks=[EvaluateAccuracy()], epochs=5,)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'bi_lstm' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "rlPnQtxPg9-2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}